{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec49290e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6294711",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2a2de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 10\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0ad1bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa0fa57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stances_headlines =  pd.read_csv('train_stances.csv')\n",
    "bodies = pd.read_csv('train_bodies.csv')\n",
    "stances_bodies = stances_headlines.merge(bodies,on='Body ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3139de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StancesDataset(Dataset):\n",
    "    def __init__(self, headlines, bodies, stances, tokenizer, max_len):\n",
    "        self.headlines = headlines\n",
    "        self.bodies = bodies\n",
    "        self.stances = stances\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.categories = {\"unrelated\": 0, \"agree\": 1, \"discuss\": 2, \"disagree\": 3}\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.headlines)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        headline = self.headlines[idx]\n",
    "        body = self.bodies[idx]\n",
    "        stance = self.stances[idx]\n",
    "        stance_label = self.categories[stance]\n",
    "        print(stance_label)\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            headline,\n",
    "            body,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        return {\n",
    "            'input_ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            \"labels\": torch.tensor([stance_label], dtype=torch.long) \n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565e3e83",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3eca60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StanceDetectionModel(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        self.l1 = torch.nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        _,pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids,\n",
    "                                 return_dict=False)\n",
    "        print('pooled output', pooled_output)\n",
    "        output = self.l1(pooled_output)\n",
    "        return F.softmax(output,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a86309",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea61ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch_size, data, model, learning_rate=0.0001, device='cpu'):\n",
    "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train().to(device)\n",
    "    num_correct_predictions = 0\n",
    "    num_samples = len(data)\n",
    "    training_loss = []\n",
    "\n",
    "    for i, input_data in enumerate(data):\n",
    "        print('Batch #', i)\n",
    "        input_ids = input_data['input_ids'].to(device)\n",
    "        attention_mask = input_data['attention_mask'].to(device)\n",
    "        token_type_ids = input_data['token_type_ids'].to(device)\n",
    "        labels = input_data['labels'].to(device).squeeze()\n",
    "        output = model(input_ids, attention_mask, token_type_ids)\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "        num_correct_predictions += torch.sum(preds == labels)\n",
    "        loss = loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        training_loss.append(loss.item())\n",
    "    return num_correct_predictions.item()/len(data), np.mean(training_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3bfd7744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    ds = StancesDataset(df['Headline'].to_numpy(),\n",
    "                        df['articleBody'].to_numpy(),\n",
    "                        df['Stance'].to_numpy(),\n",
    "                        tokenizer,\n",
    "                        max_len)\n",
    "\n",
    "\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size\n",
    "  )\n",
    "\n",
    "df_train, df_test = train_test_split(stances_bodies, test_size=0.1, random_state=RANDOM_SEED)\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)\n",
    "train_dataloader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_dataloader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_dataloader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11984577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "Batch # 0\n",
      "pooled output tensor([[ 0.1037,  0.0398,  0.8267,  ...,  0.9604, -0.8614,  0.2715],\n",
      "        [-0.0373,  0.0370,  0.9294,  ...,  0.9765, -0.8365,  0.5369],\n",
      "        [-0.9572,  0.8552,  1.0000,  ...,  1.0000,  0.9836,  0.9970],\n",
      "        ...,\n",
      "        [-0.9621,  0.8896,  1.0000,  ...,  1.0000,  0.9946,  0.9977],\n",
      "        [-0.9254,  0.8219,  1.0000,  ...,  1.0000,  0.9360,  0.9959],\n",
      "        [-0.9064,  0.8377,  1.0000,  ...,  1.0000,  0.9603,  0.9926]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Batch # 1\n",
      "pooled output tensor([[-0.9261,  0.7486,  1.0000,  ...,  1.0000,  0.9276,  0.9961],\n",
      "        [-0.8827,  0.6432,  1.0000,  ...,  1.0000,  0.7557,  0.9920],\n",
      "        [-0.9618,  0.9024,  1.0000,  ...,  1.0000,  0.9940,  0.9985],\n",
      "        ...,\n",
      "        [-0.9710,  0.8754,  1.0000,  ...,  1.0000,  0.9966,  0.9989],\n",
      "        [-0.9741,  0.9003,  1.0000,  ...,  1.0000,  0.9943,  0.9991],\n",
      "        [-0.9867,  0.9194,  1.0000,  ...,  1.0000,  0.9992,  0.9992]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "Batch # 2\n",
      "pooled output tensor([[-0.9419,  0.7415,  1.0000,  ...,  1.0000,  0.9501,  0.9977],\n",
      "        [-0.9587,  0.7249,  1.0000,  ...,  1.0000,  0.9513,  0.9951],\n",
      "        [-0.9623,  0.7934,  1.0000,  ...,  1.0000,  0.9919,  0.9996],\n",
      "        ...,\n",
      "        [-0.9501,  0.7590,  1.0000,  ...,  1.0000,  0.9774,  0.9990],\n",
      "        [-0.9564,  0.8615,  1.0000,  ...,  1.0000,  0.9878,  0.9988],\n",
      "        [-0.9691,  0.8730,  1.0000,  ...,  1.0000,  0.9854,  0.9981]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "Batch # 3\n",
      "pooled output tensor([[-0.9589,  0.7614,  1.0000,  ...,  1.0000,  0.9887,  0.9981],\n",
      "        [-0.7548,  0.3109,  0.9998,  ...,  0.9999,  0.1014,  0.9896],\n",
      "        [-0.8522,  0.3247,  0.9999,  ...,  1.0000,  0.1461,  0.9934],\n",
      "        ...,\n",
      "        [-0.7301,  0.3319,  0.9999,  ...,  1.0000,  0.3705,  0.9959],\n",
      "        [-0.7710,  0.2339,  0.9998,  ...,  1.0000, -0.2915,  0.9932],\n",
      "        [-0.9198,  0.4120,  1.0000,  ...,  1.0000,  0.8833,  0.9969]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "Batch # 4\n",
      "pooled output tensor([[-0.8792,  0.3361,  0.9999,  ...,  1.0000,  0.6291,  0.9981],\n",
      "        [-0.8911,  0.1503,  0.9999,  ...,  1.0000,  0.9042,  0.9978],\n",
      "        [-0.8912,  0.2872,  0.9999,  ...,  1.0000,  0.8233,  0.9974],\n",
      "        ...,\n",
      "        [-0.9260,  0.3662,  1.0000,  ...,  1.0000,  0.9329,  0.9983],\n",
      "        [-0.8908,  0.2173,  0.9999,  ...,  1.0000,  0.8463,  0.9992],\n",
      "        [-0.8204,  0.0610,  0.9997,  ...,  0.9999,  0.7661,  0.9940]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Batch # 5\n",
      "pooled output tensor([[-0.8616, -0.1285,  0.9986,  ...,  0.9996,  0.9808,  0.9948],\n",
      "        [-0.8837, -0.0681,  0.9996,  ...,  0.9999,  0.9741,  0.9979],\n",
      "        [-0.8340,  0.0742,  0.9999,  ...,  1.0000,  0.9808,  0.9984],\n",
      "        ...,\n",
      "        [-0.8735, -0.1130,  0.9996,  ...,  0.9999,  0.9723,  0.9974],\n",
      "        [-0.8863,  0.2427,  1.0000,  ...,  1.0000,  0.9935,  0.9993],\n",
      "        [-0.7920, -0.1607,  0.9994,  ...,  0.9998,  0.9795,  0.9960]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "Batch # 6\n",
      "pooled output tensor([[-0.8480, -0.1578,  0.9992,  ...,  0.9998,  0.9480,  0.9986],\n",
      "        [-0.6945, -0.1061,  0.9994,  ...,  0.9998,  0.8811,  0.9988],\n",
      "        [-0.8050, -0.1161,  0.9995,  ...,  0.9999,  0.9584,  0.9990],\n",
      "        ...,\n",
      "        [-0.8904,  0.1069,  0.9996,  ...,  0.9999,  0.9557,  0.9980],\n",
      "        [-0.8450,  0.1204,  0.9998,  ...,  1.0000,  0.8657,  0.9995],\n",
      "        [-0.8293, -0.0658,  0.9997,  ...,  0.9999,  0.8939,  0.9991]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "Batch # 7\n",
      "pooled output tensor([[-7.8954e-01, -7.1935e-02,  9.9929e-01,  ...,  9.9988e-01,\n",
      "          6.0853e-01,  9.9946e-01],\n",
      "        [-7.0135e-01, -3.7250e-02,  9.9830e-01,  ...,  9.9977e-01,\n",
      "          5.3845e-01,  9.9833e-01],\n",
      "        [-7.4518e-01, -7.4518e-02,  9.9954e-01,  ...,  9.9992e-01,\n",
      "          8.0114e-01,  9.9923e-01],\n",
      "        ...,\n",
      "        [-6.5608e-01, -9.1109e-02,  9.9452e-01,  ...,  9.9886e-01,\n",
      "          6.8177e-01,  9.9758e-01],\n",
      "        [-8.0949e-01,  6.3166e-02,  9.9992e-01,  ...,  9.9999e-01,\n",
      "          9.1782e-01,  9.9967e-01],\n",
      "        [-8.1969e-01,  4.6320e-04,  9.9967e-01,  ...,  9.9992e-01,\n",
      "          9.0325e-01,  9.9949e-01]], grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "Batch # 8\n",
      "pooled output tensor([[-0.8426,  0.0031,  0.9997,  ...,  0.9999,  0.4009,  0.9995],\n",
      "        [-0.8445, -0.0290,  0.9992,  ...,  0.9998,  0.6790,  0.9992],\n",
      "        [-0.7967, -0.0739,  0.9982,  ...,  0.9997,  0.5313,  0.9989],\n",
      "        ...,\n",
      "        [-0.9009,  0.2539,  0.9998,  ...,  0.9999,  0.6752,  0.9997],\n",
      "        [-0.8372,  0.1102,  0.9997,  ...,  0.9999,  0.7119,  0.9996],\n",
      "        [-0.7752,  0.1151,  0.9989,  ...,  0.9998,  0.2693,  0.9995]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "Batch # 9\n",
      "pooled output tensor([[-0.7824,  0.1822,  0.9990,  ...,  0.9998,  0.6178,  0.9983],\n",
      "        [-0.7550,  0.1738,  0.9990,  ...,  0.9999,  0.3547,  0.9995],\n",
      "        [-0.7831, -0.0273,  0.9990,  ...,  0.9998,  0.6928,  0.9992],\n",
      "        ...,\n",
      "        [-0.8453,  0.1784,  0.9996,  ...,  0.9999,  0.3646,  0.9996],\n",
      "        [-0.8004,  0.0811,  0.9997,  ...,  0.9999,  0.5020,  0.9994],\n",
      "        [-0.8894,  0.2987,  0.9998,  ...,  1.0000,  0.6794,  0.9996]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Batch # 10\n",
      "pooled output tensor([[-0.8911,  0.1204,  0.9998,  ...,  1.0000,  0.7748,  0.9996],\n",
      "        [-0.8977,  0.3019,  0.9998,  ...,  0.9999,  0.6752,  0.9992],\n",
      "        [-0.8778,  0.2068,  0.9998,  ...,  1.0000,  0.8532,  0.9997],\n",
      "        ...,\n",
      "        [-0.7653,  0.2389,  0.9989,  ...,  0.9999,  0.5381,  0.9992],\n",
      "        [-0.8501,  0.1349,  0.9998,  ...,  1.0000,  0.7135,  0.9996],\n",
      "        [-0.8700,  0.1236,  0.9998,  ...,  0.9999,  0.8288,  0.9995]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "Batch # 11\n",
      "pooled output tensor([[-0.8716,  0.2865,  0.9998,  ...,  1.0000,  0.7128,  0.9995],\n",
      "        [-0.9304,  0.4074,  0.9999,  ...,  1.0000,  0.7721,  0.9997],\n",
      "        [-0.9292,  0.4133,  1.0000,  ...,  1.0000,  0.8715,  0.9997],\n",
      "        ...,\n",
      "        [-0.8986,  0.2149,  0.9997,  ...,  0.9999,  0.8858,  0.9981],\n",
      "        [-0.8675,  0.1984,  0.9998,  ...,  0.9999,  0.3797,  0.9992],\n",
      "        [-0.8787,  0.1824,  0.9998,  ...,  0.9999,  0.6140,  0.9997]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Batch # 12\n",
      "pooled output tensor([[-0.9073,  0.3027,  0.9999,  ...,  1.0000,  0.6604,  0.9997],\n",
      "        [-0.9163,  0.3473,  0.9999,  ...,  1.0000,  0.8487,  0.9996],\n",
      "        [-0.8979,  0.3310,  1.0000,  ...,  1.0000,  0.9431,  0.9997],\n",
      "        ...,\n",
      "        [-0.9107,  0.4306,  0.9999,  ...,  1.0000,  0.7529,  0.9993],\n",
      "        [-0.9149,  0.2578,  0.9999,  ...,  1.0000,  0.7848,  0.9996],\n",
      "        [-0.8831,  0.2863,  0.9999,  ...,  1.0000,  0.5975,  0.9996]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "Batch # 13\n",
      "pooled output tensor([[-0.8688,  0.3962,  0.9998,  ...,  0.9999,  0.4051,  0.9994],\n",
      "        [-0.8819,  0.3758,  0.9997,  ...,  0.9999,  0.4925,  0.9994],\n",
      "        [-0.8834,  0.3145,  0.9999,  ...,  1.0000,  0.6090,  0.9997],\n",
      "        ...,\n",
      "        [-0.8892,  0.4213,  0.9998,  ...,  1.0000,  0.3948,  0.9997],\n",
      "        [-0.9120,  0.4251,  0.9999,  ...,  1.0000,  0.7716,  0.9998],\n",
      "        [-0.9153,  0.4886,  1.0000,  ...,  1.0000,  0.6212,  0.9998]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "2\n",
      "Batch # 14\n",
      "pooled output tensor([[-0.9060,  0.2048,  0.9998,  ...,  1.0000,  0.5192,  0.9996],\n",
      "        [-0.9374,  0.4360,  1.0000,  ...,  1.0000,  0.7055,  0.9996],\n",
      "        [-0.8868,  0.3347,  0.9999,  ...,  1.0000,  0.1463,  0.9997],\n",
      "        ...,\n",
      "        [-0.9068,  0.4089,  0.9999,  ...,  1.0000,  0.6905,  0.9997],\n",
      "        [-0.9137,  0.3917,  0.9999,  ...,  1.0000,  0.6101,  0.9995],\n",
      "        [-0.9276,  0.3491,  0.9999,  ...,  1.0000,  0.6802,  0.9998]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m StanceDetectionModel(n_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i  \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 5\u001b[0m     accuracy, mean_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining accuracy at epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean loss at epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(batch_size, data, model, learning_rate, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m num_correct_predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(preds \u001b[38;5;241m==\u001b[39m labels)\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output, labels)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp-final-proj/lib/python3.8/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp-final-proj/lib/python3.8/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "batch_size=10\n",
    "model = StanceDetectionModel(n_classes=4)\n",
    "for i  in range(epochs):\n",
    "    accuracy, mean_loss = train(batch_size,train_dataloader, model)\n",
    "    print(f'Training accuracy at epoch {i} is {accuracy}')\n",
    "    print(f'Mean loss at epoch {i} is {mean_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedaddc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ef2212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc6dadb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
